(window.webpackJsonp=window.webpackJsonp||[]).push([[141],{502:function(t,a,e){"use strict";e.r(a);var s=e(1),n=Object(s.a)({},(function(){var t=this,a=t.$createElement,e=t._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"introduction-guide"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#introduction-guide"}},[t._v("#")]),t._v(" Introduction Guide")]),t._v(" "),e("p",[t._v("Let’s say we have a few raw data files. It’s been just collected by the data researchers, and the quality of data is not yet perfect. To tell you more, they haven’t even removed the comments from the first row!")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! cat data"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("countries"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("csv\n")])])]),e("pre",[e("code",[t._v("# clean this data!\nid,neighbor_id,name,population\n1,Ireland,Britain,67\n2,3,France,n/a,find the population\n3,22,Germany,83\n4,,Italy,60\n5\n")])]),t._v(" "),e("p",[t._v("As we can see, it’s a data containing information about European countries and their populations. Also, it’s easy to notice that there are two fields having a relationship based on a country’s identifier.")]),t._v(" "),e("h2",{attrs:{id:"describing-data"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#describing-data"}},[t._v("#")]),t._v(" Describing Data")]),t._v(" "),e("p",[t._v("First of all, we’re going to describe our dataset. Frictionless uses powerful "),e("a",{attrs:{href:"https://specs.frictionlessdata.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Frictionless Data Specifications"),e("OutboundLink")],1),t._v(". They are very handy to describe:")]),t._v(" "),e("ul",[e("li",[t._v("a data table - "),e("a",{attrs:{href:"https://specs.frictionlessdata.io/table-schema/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Table Schema"),e("OutboundLink")],1)]),t._v(" "),e("li",[t._v("a data resource - "),e("a",{attrs:{href:"https://specs.frictionlessdata.io/data-resource/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Data Resource"),e("OutboundLink")],1)]),t._v(" "),e("li",[t._v("a data package - "),e("a",{attrs:{href:"https://specs.frictionlessdata.io/data-package/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Data Package"),e("OutboundLink")],1)]),t._v(" "),e("li",[t._v("and other objects")])]),t._v(" "),e("p",[t._v("Let’s describe the "),e("code",[t._v("countries")]),t._v(" table:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! frictionless describe data"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("countries"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("csv\n")])])]),e("pre",[e("code",[t._v("---\nmetadata: data/countries.csv\n---\n\ncompression: 'no'\ncompressionPath: ''\ncontrol:\n  newline: ''\ndialect:\n  headerRows:\n    - 2\nencoding: utf-8\nformat: csv\nhashing: md5\nname: countries\npath: data/countries.csv\nprofile: tabular-data-resource\nquery: {}\nschema:\n  fields:\n    - name: id\n      type: integer\n    - name: neighbor_id\n      type: string\n    - name: name\n      type: string\n    - name: population\n      type: string\nscheme: file\nstats:\n  bytes: 136\n  fields: 4\n  hash: b0481536cb4ab3e5db64f0feede627fa\n  rows: 5\n")])]),t._v(" "),e("p",[t._v("As we can see, Frictionless was smart enough to understand that the first row contains a comment. It’s good, but we still have a few problems:")]),t._v(" "),e("ul",[e("li",[t._v("we use "),e("code",[t._v("n/a")]),t._v(" as a missing values marker")]),t._v(" "),e("li",[e("code",[t._v("neighbor_id")]),t._v(" must be numerical: let’s edit the schema")]),t._v(" "),e("li",[e("code",[t._v("population")]),t._v(" must be numerical: setting proper missing values will solve it")]),t._v(" "),e("li",[t._v("there is a relation between the "),e("code",[t._v("id")]),t._v(" and "),e("code",[t._v("neighbor_id")]),t._v(" fields")])]),t._v(" "),e("p",[t._v("Let’s update our metadata and save it to the disc:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" describe\n\nresource "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" describe"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"data/countries.csv"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" infer_missing_values"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"n/a"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nresource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_field"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"neighbor_id"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),e("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"integer"')]),t._v("\nresource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreign_keys"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fields"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"neighbor_id"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"reference"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"resource"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fields"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nresource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_yaml"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tmp/countries.resource.yaml"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("Let’s see what we have created:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! cat tmp"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("countries"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yaml\n")])])]),e("pre",[e("code",[t._v("compression: 'no'\ncompressionPath: ''\ncontrol:\n  newline: ''\ndialect:\n  headerRows:\n    - 2\nencoding: utf-8\nformat: csv\nhashing: md5\nname: countries\npath: data/countries.csv\nprofile: tabular-data-resource\nquery: {}\nschema:\n  fields:\n    - name: id\n      type: integer\n    - name: neighbor_id\n      type: integer\n    - name: name\n      type: string\n    - name: population\n      type: integer\n  foreignKeys:\n    - fields:\n        - neighbor_id\n      reference:\n        fields:\n          - id\n        resource: ''\n  missingValues:\n    - ''\n    - n/a\nscheme: file\nstats:\n  bytes: 136\n  fields: 4\n  hash: b0481536cb4ab3e5db64f0feede627fa\n  rows: 5\n")])]),t._v(" "),e("p",[t._v("It has the same metadata as we saw above but also includes our editing related to missing values and data types. We didn’t change all the wrong data types manually because providing proper missing values had fixed it automatically. Now we have a resource descriptor. In the next section, we will show why metadata matters and how to use it.")]),t._v(" "),e("h2",{attrs:{id:"extracting-data"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#extracting-data"}},[t._v("#")]),t._v(" Extracting Data")]),t._v(" "),e("p",[t._v("It’s time to try extracting our data as a table. As a first naive attempt, we will ignore the metadata we saved on the previous step:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! frictionless extract data"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("countries"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("csv\n")])])]),e("pre",[e("code",[t._v("---\ndata: data/countries.csv\n---\n\n==  ===========  =======  ==========\nid  neighbor_id  name     population\n==  ===========  =======  ==========\n 1  Ireland      Britain  67\n 2  3            France   n/a\n 3  22           Germany  83\n 4  None         Italy    60\n 5  None         None     None\n==  ===========  =======  ==========\n")])]),t._v(" "),e("p",[t._v("Actually, it doesn’t look terrible, but in reality, data like this is not quite useful:")]),t._v(" "),e("ul",[e("li",[t._v("it’s not possible to export this data e.g., to SQL because integers are mixed with strings")]),t._v(" "),e("li",[t._v("there is still a basically empty row we don’t want to have")]),t._v(" "),e("li",[t._v("there is a clear mistake in Germany’s neighborhood!")])]),t._v(" "),e("p",[t._v("Let’s use the metadata we save to try extracting data with the help of Frictionless Data specifications:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! frictionless extract tmp"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("countries"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yaml "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("basepath "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n")])])]),e("pre",[e("code",[t._v("---\ndata: tmp/countries.resource.yaml\n---\n\n==  ===========  =======  ==========\nid  neighbor_id  name     population\n==  ===========  =======  ==========\n 1  None         Britain          67\n 2            3  France   None\n 3           22  Germany          83\n 4  None         Italy            60\n 5  None         None     None\n==  ===========  =======  ==========\n")])]),t._v(" "),e("p",[t._v("It’s now much better! Numerical fields are numerical fields, and there are no more textual missing values markers. We can’t see in the command-line, but missing values are now "),e("code",[t._v("None")]),t._v(" values in Python, and the data can be e.g., exported to SQL. Although, it’s still not ready for being published. In the next section, we will validate it!")]),t._v(" "),e("h2",{attrs:{id:"validating-data"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#validating-data"}},[t._v("#")]),t._v(" Validating Data")]),t._v(" "),e("p",[t._v("Data validation with Frictionless is as easy as describing or extracting data:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! frictionless validate data"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("countries"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("csv\n")])])]),e("pre",[e("code",[t._v('---\ninvalid: data/countries.csv\n---\n\n===  =====  ============  =============================================================================\nrow  field  code          message\n===  =====  ============  =============================================================================\n  4      5  extra-cell    Row at position "4" has an extra value in field at position "5"\n  7      2  missing-cell  Row at position "7" has a missing cell in field "neighbor_id" at position "2"\n  7      3  missing-cell  Row at position "7" has a missing cell in field "name" at position "3"\n  7      4  missing-cell  Row at position "7" has a missing cell in field "population" at position "4"\n===  =====  ============  =============================================================================\n')])]),t._v(" "),e("p",[t._v("Ahh, we had seen that coming. The data is not valid; there are some missing and extra cells. But wait a minute, in the first step, we created the metadata file with more information about our table. We have to use it.")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! frictionless validate tmp"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("countries"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yaml "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("basepath "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n")])])]),e("pre",[e("code",[t._v('---\ninvalid: ./data/countries.csv\n---\n\n===  =====  =================  ==================================================================================================================================\nrow  field  code               message\n===  =====  =================  ==================================================================================================================================\n  3      2  type-error         The cell "Ireland" in row at position "3" and field "neighbor_id" at position "2" has incompatible type: type is "integer/default"\n  4      5  extra-cell         Row at position "4" has an extra value in field at position "5"\n  5  None   foreign-key-error  The row at position "5" does not conform to the foreign key constraint: not found in the lookup table\n  7      2  missing-cell       Row at position "7" has a missing cell in field "neighbor_id" at position "2"\n  7      3  missing-cell       Row at position "7" has a missing cell in field "name" at position "3"\n  7      4  missing-cell       Row at position "7" has a missing cell in field "population" at position "4"\n===  =====  =================  ==================================================================================================================================\n')])]),t._v(" "),e("p",[t._v("Now it’s even worse, but regarding data validation errors, the more, the better, actually. Thanks to the metadata, we were able to reveal some critical errors:")]),t._v(" "),e("ul",[e("li",[t._v("the bad data types, i.e. "),e("code",[t._v("Ireland")]),t._v(" instead of an id")]),t._v(" "),e("li",[t._v("the bad relation between "),e("code",[t._v("id")]),t._v(" and "),e("code",[t._v("neighbor_id")]),t._v(": we don’t have a country with id 22")])]),t._v(" "),e("p",[t._v("In the next section, we will clean up the data.")]),t._v(" "),e("h2",{attrs:{id:"transforming-data"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#transforming-data"}},[t._v("#")]),t._v(" Transforming Data")]),t._v(" "),e("blockquote",[e("p",[t._v("Currently, the pipeline capabilities are under construction. It’s already possible to run "),e("code",[t._v("dataflows")]),t._v(" spec as a pipeline, and more is coming but, for now, we will use Python programming for data cleaning.")])]),t._v(" "),e("p",[t._v("We will use metadata to fix all the data type problems automatically. The only two things we need to handle manually:")]),t._v(" "),e("ul",[e("li",[t._v("France’s population")]),t._v(" "),e("li",[t._v("Germany’s neighborhood")])]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Table\n\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("source")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    resource "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tmp/countries.resource.yaml"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" basepath"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" row "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_row_stream"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" row"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"France"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            row"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"population"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("67")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" row"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Germany"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            row"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"neighbor_id"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" row"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("yield")]),t._v(" row\n\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" Table"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" table"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    table"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tmp/countries-cleaned.csv"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("Finally, we’ve got the cleaned version of our data, which can be exported to a database or published. We have used a CSV as an output format but could have used Excel, JSON, SQL, and others.")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! cat tmp"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("countries"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("cleaned"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("csv\n")])])]),e("p",[t._v("We also need to update our metadata file:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" describe\n\nsource "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tmp/countries.resource.yaml"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" describe"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tmp/countries-cleaned.csv"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreign_keys "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" source"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreign_keys\ntarget"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_yaml"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tmp/countries-cleaned.resource.yaml"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("After running this script our metadata will be:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! cat tmp"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("countries"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("cleaned"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yaml\n")])])]),e("pre",[e("code",[t._v("compression: 'no'\ncompressionPath: ''\ncontrol:\n  newline: ''\ndialect: {}\nencoding: utf-8\nformat: csv\nhashing: md5\nname: countries-cleaned\npath: tmp/countries-cleaned.csv\nprofile: tabular-data-resource\nquery: {}\nschema:\n  fields:\n    - name: id\n      type: integer\n    - name: neighbor_id\n      type: any\n    - name: name\n      type: string\n    - name: population\n      type: integer\n  foreignKeys:\n    - fields:\n        - neighbor_id\n      reference:\n        fields:\n          - id\n        resource: ''\nscheme: file\nstats:\n  bytes: 91\n  fields: 4\n  hash: d32b9e60ed03baae266b9ad5d3342252\n  rows: 4\n")])]),t._v(" "),e("p",[t._v("Basically, that’s it; now, we have a valid data file and a corresponding metadata file. It can be shared with other people or stored without fear of type errors or other problems making data research not reproducible.")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! ls "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("la tmp"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("countries"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("cleaned"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("csv tmp"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("country"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yaml\n")])])]),e("pre",[e("code",[t._v("-rw------- 1 roll roll  91 дек  2 11:42 tmp/countries-cleaned.csv\n-rw------- 1 roll roll 926 дек  2 11:41 tmp/country.resource.yaml\n")])]),t._v(" "),e("p",[t._v("In the next articles, we will explore more advanced Frictionless’ functionality.")])])}),[],!1,null,null,null);a.default=n.exports}}]);