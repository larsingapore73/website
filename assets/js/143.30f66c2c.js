(window.webpackJsonp=window.webpackJsonp||[]).push([[143],{503:function(t,a,s){"use strict";s.r(a);var n=s(1),e=Object(n.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"validating-data"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#validating-data"}},[t._v("#")]),t._v(" Validating Data")]),t._v(" "),s("p",[t._v("Tabular data validation is a process of identifying tabular problems that have place in your data for further correction. Let’s explore how Frictionless helps to achieve these tasks using an invalid data table example:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("! cat data"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("capital"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("invalid"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("csv\n")])])]),s("pre",[s("code",[t._v("id,name,name\n1,London,Britain\n2,Berlin,Germany\n3,Paris,France\n4,Madrid,Spain\n5,Rome,Italy\n6,Zagreb,Croatia\n7,Athens,Greece\n8,Vienna,Austria\n8,Warsaw\n\nx,Tokio,Japan,review\n")])]),t._v(" "),s("p",[t._v("Using the command-line interface we can validate this file. Frictionless provides comprehensive error details so it’s self-explanatory. Continue reading to learn the validation process in-details.")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("! frictionless validate data"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("capital"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("invalid"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("csv\n")])])]),s("pre",[s("code",[t._v('---\ninvalid: data/capital-invalid.csv\n---\n\n====  =====  ================  ====================================================================================================================\nrow   field  code              message\n====  =====  ================  ====================================================================================================================\nNone      3  duplicate-header  Header "name" in field at position "3" is duplicated to header in another field: at position "2"\n  10      3  missing-cell      Row at position "10" has a missing cell in field "name2" at position "3"\n  11  None   blank-row         Row at position "11" is completely blank\n  12      4  extra-cell        Row at position "12" has an extra value in field at position "4"\n  12      1  type-error        The cell "x" in row at position "12" and field "id" at position "1" has incompatible type: type is "integer/default"\n====  =====  ================  ====================================================================================================================\n')])]),t._v(" "),s("h2",{attrs:{id:"validate-functions"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#validate-functions"}},[t._v("#")]),t._v(" Validate Functions")]),t._v(" "),s("p",[t._v("The high-level interface for validating data provided by Frictionless is a set of "),s("code",[t._v("validate")]),t._v(" functions:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("validate")]),t._v(": it will detect the source type and validate data accordingly")]),t._v(" "),s("li",[s("code",[t._v("validate_schema")]),t._v(": it validates a schema’s metadata")]),t._v(" "),s("li",[s("code",[t._v("validate_resource")]),t._v(": it validates a resource’s data and metadata")]),t._v(" "),s("li",[s("code",[t._v("validate_package")]),t._v(": it validates a package’s data and metadata")]),t._v(" "),s("li",[s("code",[t._v("validate_inquiery")]),t._v(": it validates a special "),s("code",[t._v("Inquiery")]),t._v(" object which represents a validation task instruction")]),t._v(" "),s("li",[s("code",[t._v("validate_table")]),t._v(": it validates a table")])]),t._v(" "),s("p",[t._v("In command-line, there is only 1 command but there is a flag to adjust the behavior:")]),t._v(" "),s("div",{staticClass:"language-sh extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sh"}},[s("code",[t._v("$ frictionless validate\n$ frictionless validate --source-type schema\n$ frictionless validate --source-type resource\n$ frictionless validate --source-type package\n$ frictionless validate --source-type inquiry\n$ frictionless validate --source-type table\n")])])]),s("h3",{attrs:{id:"validating-schema"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#validating-schema"}},[t._v("#")]),t._v(" Validating Schema")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("validate_schema")]),t._v(" function is the only function validating solely metadata. Let’s create a invalid table schema:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Schema\n\nschema "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Schema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nschema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fields "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# must be a list")]),t._v("\nschema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_yaml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tmp/invalid.schema.yaml'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("And validate it using the command-line interface:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("! frictionless validate tmp"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("invalid"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yaml\n")])])]),s("pre",[s("code",[t._v('---\ninvalid: tmp/invalid.schema.yaml\n---\n============  ===============================================================================================================================================================================\ncode          message\n============  ===============================================================================================================================================================================\nschema-error  The data source could not be successfully described by the invalid Table Schema: "{} is not of type \'array\'" at "fields" in metadata and at "properties/fields/type" in profile\n============  ===============================================================================================================================================================================\n')])]),t._v(" "),s("p",[t._v("Schema validation can be very useful when you work with different classes of tables and create schemas for them. Using this function you can ensure that the metadata is valid.")]),t._v(" "),s("h3",{attrs:{id:"validating-resource"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#validating-resource"}},[t._v("#")]),t._v(" Validating Resource")]),t._v(" "),s("p",[t._v("As it was shown in the “Describing Data” guide a resource is a container having both metadata and data. We need to create a resource descriptor to validate it:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("! frictionless describe data"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("capital"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("invalid"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("csv "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("json "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" tmp"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("capital"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("json\n")])])]),s("p",[t._v("Let’s now use the command-line interface to ensure that we are getting the same result as we had withouth using a resource:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("! frictionless validate tmp"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("capital"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("json "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("basepath "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n")])])]),s("pre",[s("code",[t._v('---\ninvalid: ./data/capital-invalid.csv\n---\n\n====  =====  ================  ====================================================================================================================\nrow   field  code              message\n====  =====  ================  ====================================================================================================================\nNone      3  duplicate-header  Header "name" in field at position "3" is duplicated to header in another field: at position "2"\n  10      3  missing-cell      Row at position "10" has a missing cell in field "name2" at position "3"\n  11  None   blank-row         Row at position "11" is completely blank\n  12      4  extra-cell        Row at position "12" has an extra value in field at position "4"\n  12      1  type-error        The cell "x" in row at position "12" and field "id" at position "1" has incompatible type: type is "integer/default"\n====  =====  ================  ====================================================================================================================\n')])]),t._v(" "),s("p",[t._v("Okay, why do we need to use a resource descriptor if the result is the same? The reason is metadata + data packaging. Let’s extend our resource descriptor:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" describe\n\nresource "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" describe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data/capital-invalid.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nresource"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'bytes'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# wrong")]),t._v("\nresource"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'hash'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'ae23c74693ca2d3f0e38b9ba3570775b'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# wrong")]),t._v("\nresource"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_yaml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tmp/capital.resource.yaml'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("We have added a few bad metrics to our resource descriptor. The validation below reports it in addition to all the errors we had before. This example is showing how concepts like Data Resource can be extremely useful when working with data.")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("! frictionless validate tmp"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("capital"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yaml "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("basepath "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n")])])]),s("pre",[s("code",[t._v('---\ninvalid: ./data/capital-invalid.csv\n---\n\n====  =====  ================  ====================================================================================================================\nrow   field  code              message\n====  =====  ================  ====================================================================================================================\nNone      3  duplicate-header  Header "name" in field at position "3" is duplicated to header in another field: at position "2"\n  10      3  missing-cell      Row at position "10" has a missing cell in field "name2" at position "3"\n  11  None   blank-row         Row at position "11" is completely blank\n  12      4  extra-cell        Row at position "12" has an extra value in field at position "4"\n  12      1  type-error        The cell "x" in row at position "12" and field "id" at position "1" has incompatible type: type is "integer/default"\n====  =====  ================  ====================================================================================================================\n')])]),t._v(" "),s("h3",{attrs:{id:"validating-package"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#validating-package"}},[t._v("#")]),t._v(" Validating Package")]),t._v(" "),s("p",[t._v("A package is a set of resources + additional metadata. To showcase a package validation we need one more tabular file:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("! cat data"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("capital"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("valid"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("csv\n")])])]),s("pre",[s("code",[t._v("id,name\n1,London\n2,Berlin\n3,Paris\n4,Madrid\n5,Rome\n")])]),t._v(" "),s("p",[t._v("Let’s describe and validate a package:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("! frictionless describe data"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("capital"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("csv "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("json "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" tmp"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("capital"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("package"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("json\n! frictionless validate tmp"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("capital"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("package"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("json "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("basepath "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n")])])]),s("pre",[s("code",[t._v('---\ninvalid: ./data/capital-invalid.csv\n---\n\n====  =====  ================  ====================================================================================================================\nrow   field  code              message\n====  =====  ================  ====================================================================================================================\nNone      3  duplicate-header  Header "name" in field at position "3" is duplicated to header in another field: at position "2"\n  10      3  missing-cell      Row at position "10" has a missing cell in field "name2" at position "3"\n  11  None   blank-row         Row at position "11" is completely blank\n  12      4  extra-cell        Row at position "12" has an extra value in field at position "4"\n  12      1  type-error        The cell "x" in row at position "12" and field "id" at position "1" has incompatible type: type is "integer/default"\n====  =====  ================  ====================================================================================================================\n\n\n---\nvalid: ./data/capital-valid.csv\n---\n')])]),t._v(" "),s("p",[t._v("As we can see, the result is pretty straight-forward and expected: we have one invalid resource and one valid. One important note regarding the package validation: if there are more than one resource, it will use multiprocessing to speed up the process")]),t._v(" "),s("h3",{attrs:{id:"validating-inquiry"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#validating-inquiry"}},[t._v("#")]),t._v(" Validating Inquiry")]),t._v(" "),s("p",[t._v("The Inquiry gives you an ability to create arbitrary validation jobs containing a set of individual validation taks. Let’s create an inquiry that includes an individual file validation and a resource validation:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Inquiry\n\ninquiry "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Inquiry"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tasks'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'source'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data/capital-valid.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'source'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tmp/capital.resource.json'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'basepath'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ninquiry"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_yaml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tmp/capital.inquiry.yaml'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("Tasks in the Inquiry accept the same arguments written in camelCase as the corresponding "),s("code",[t._v("validate")]),t._v(" functions have. As usual, let’ run validation:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("! frictionless validate tmp"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("capital"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inquiry"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yaml\n")])])]),s("pre",[s("code",[t._v('---\nvalid: data/capital-valid.csv\n---\n---\ninvalid: ./data/capital-invalid.csv\n---\n\n====  =====  ================  ====================================================================================================================\nrow   field  code              message\n====  =====  ================  ====================================================================================================================\nNone      3  duplicate-header  Header "name" in field at position "3" is duplicated to header in another field: at position "2"\n  10      3  missing-cell      Row at position "10" has a missing cell in field "name2" at position "3"\n  11  None   blank-row         Row at position "11" is completely blank\n  12      4  extra-cell        Row at position "12" has an extra value in field at position "4"\n  12      1  type-error        The cell "x" in row at position "12" and field "id" at position "1" has incompatible type: type is "integer/default"\n====  =====  ================  ====================================================================================================================\n')])]),t._v(" "),s("p",[t._v("At first sight, it’s no clear why such a construct exists but when your validation workflow gets complex, the Inquiry can provide a lot of flexibility and power. Last but not least, the Inquiry will use multiprocessing if there are more than 1 task provided.")]),t._v(" "),s("h3",{attrs:{id:"validating-table"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#validating-table"}},[t._v("#")]),t._v(" Validating Table")]),t._v(" "),s("p",[t._v("All the functions above except for "),s("code",[t._v("validate_schema")]),t._v(" are just wrappers over the "),s("code",[t._v("validate_table")]),t._v(" function. Below we will be talking a lot about the table validation so here will just provide a simple example:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("! frictionless validate data"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("capital"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("invalid"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("csv "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("pick"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("errors duplicate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("header\n")])])]),s("pre",[s("code",[t._v('---\ninvalid: data/capital-invalid.csv\n---\n\n====  =====  ================  ================================================================================================\nrow   field  code              message\n====  =====  ================  ================================================================================================\nNone      3  duplicate-header  Header "name" in field at position "3" is duplicated to header in another field: at position "2"\n====  =====  ================  ================================================================================================\n')])]),t._v(" "),s("p",[t._v("Please keep reading to learn about the table validation in-detail.")]),t._v(" "),s("h2",{attrs:{id:"validation-options"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#validation-options"}},[t._v("#")]),t._v(" Validation Options")]),t._v(" "),s("p",[t._v("Let’s overview options that the described "),s("code",[t._v("validate")]),t._v(" functions accept:")]),t._v(" "),s("h3",{attrs:{id:"schema-inquiry"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#schema-inquiry"}},[t._v("#")]),t._v(" Schema/Inquiry")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("validate_schema")]),t._v(" and "),s("code",[t._v("validate_inquiry")]),t._v(" don’t accept any options in addition to "),s("code",[t._v("source")]),t._v(".")]),t._v(" "),s("h3",{attrs:{id:"resource-package"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#resource-package"}},[t._v("#")]),t._v(" Resource/Package")]),t._v(" "),s("p",[t._v("The Resource and Package incapsulate most of information within their descriptor so the amount of additional options is really limited:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("basepath")]),t._v(": base path for a resource/package")]),t._v(" "),s("li",[s("code",[t._v("noinfer")]),t._v(": a flag disabling an infer function call")])]),t._v(" "),s("h3",{attrs:{id:"table"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#table"}},[t._v("#")]),t._v(" Table")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("validate_table")]),t._v(" function accept most of the "),s("code",[t._v("describe/extract")]),t._v(" function’s options:")]),t._v(" "),s("ul",[s("li",[t._v("File Details (see “Extracting Data”)")]),t._v(" "),s("li",[t._v("File Control (see “Extracting Data”)")]),t._v(" "),s("li",[t._v("Table Dialect (see “Extracting Data”)")]),t._v(" "),s("li",[t._v("Table Query (see “Extracting Data”)")]),t._v(" "),s("li",[t._v("Header Options (see “Extracting Data”)")]),t._v(" "),s("li",[t._v("Schema Options (see “Extracting Data”)")]),t._v(" "),s("li",[t._v("Integrity Options (see “Extracting Data”)")]),t._v(" "),s("li",[t._v("Infer Options (see “Describing Data”)")]),t._v(" "),s("li",[t._v("Errors Options")]),t._v(" "),s("li",[t._v("Memory Options")]),t._v(" "),s("li",[t._v("Checks Options")])]),t._v(" "),s("h2",{attrs:{id:"validation-report"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#validation-report"}},[t._v("#")]),t._v(" Validation Report")]),t._v(" "),s("p",[t._v("All the "),s("code",[t._v("validate")]),t._v(" functions return the Validation Report. It’s an unified object containing information about a validation: source details, found error, etc. Let’s explore a report:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" validate\n\nreport "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data/capital-invalid.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pick_errors"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'duplicate-header'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("report"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("pre",[s("code",[t._v("{'errors': [],\n 'stats': {'errors': 1, 'tables': 1},\n 'tables': [{'compression': 'no',\n             'compressionPath': '',\n             'dialect': {},\n             'encoding': 'utf-8',\n             'errors': [{'cell': 'name',\n                         'cells': ['id', 'name', 'name'],\n                         'code': 'duplicate-header',\n                         'description': 'Two columns in the header row have '\n                                        'the same value. Column names should '\n                                        'be unique.',\n                         'fieldName': 'name2',\n                         'fieldNumber': 3,\n                         'fieldPosition': 3,\n                         'message': 'Header \"name\" in field at position \"3\" is '\n                                    'duplicated to header in another field: at '\n                                    'position \"2\"',\n                         'name': 'Duplicate Header',\n                         'note': 'at position \"2\"',\n                         'tags': ['#head', '#structure']}],\n             'format': 'csv',\n             'hashing': 'md5',\n             'header': ['id', 'name', 'name'],\n             'partial': False,\n             'path': 'data/capital-invalid.csv',\n             'query': {},\n             'schema': {'fields': [{'name': 'id', 'type': 'integer'},\n                                   {'name': 'name', 'type': 'string'},\n                                   {'name': 'name2', 'type': 'string'}]},\n             'scheme': 'file',\n             'scope': ['duplicate-header'],\n             'stats': {'bytes': 171,\n                       'errors': 1,\n                       'fields': 3,\n                       'hash': 'dcdeae358cfd50860c18d953e021f836',\n                       'rows': 11},\n             'time': 0.019,\n             'valid': False}],\n 'time': 0.019,\n 'valid': False,\n 'version': '3.38.1'}\n")])]),t._v(" "),s("p",[t._v("As we can see, there are a lot of information; you can find its details description in “API Reference”. Errors are groupped by tables; for some validation there are can be dozens of tables. Let’s use the "),s("code",[t._v("report.flatten")]),t._v(" function to simplify errors representation:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" validate\n\nreport "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data/capital-invalid.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pick_errors"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'duplicate-header'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("report"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'rowPosition'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'fieldPosition'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'code'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'message'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("pre",[s("code",[t._v("[[None,\n  3,\n  'duplicate-header',\n  'Header \"name\" in field at position \"3\" is duplicated to header in another '\n  'field: at position \"2\"']]\n")])]),t._v(" "),s("p",[t._v("In some situation, an error can’t be associated with a table; then it goes to the top-level "),s("code",[t._v("report.errors")]),t._v(" property:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" validate_schema\n\nreport "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate_schema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'bad.json'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("report"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("pre",[s("code",[t._v("{'errors': [{'code': 'schema-error',\n             'description': 'Provided schema is not valid.',\n             'message': 'The data source could not be successfully described '\n                        'by the invalid Table Schema: cannot extract metadata '\n                        '\"bad.json\" because \"[Errno 2] No such file or '\n                        'directory: \\'bad.json\\'\"',\n             'name': 'Schema Error',\n             'note': 'cannot extract metadata \"bad.json\" because \"[Errno 2] No '\n                     'such file or directory: \\'bad.json\\'\"',\n             'tags': ['#table', '#schema']}],\n 'stats': {'errors': 1, 'tables': 0},\n 'tables': [],\n 'time': 0.0,\n 'valid': False,\n 'version': '3.38.1'}\n")])]),t._v(" "),s("h2",{attrs:{id:"validation-errors"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#validation-errors"}},[t._v("#")]),t._v(" Validation Errors")]),t._v(" "),s("p",[t._v("The Error object is at the heart of the validation process. The Report has "),s("code",[t._v("report.errors")]),t._v(" and "),s("code",[t._v("report.tables[].errors")]),t._v(" properties that can contain the Error object. Let’s explore it:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" validate\n\nreport "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data/capital-invalid.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pick_errors"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'duplicate-header'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nerror "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" report"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("error "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# it's only available for 1 table / 1 error sitution")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v("f'Code: \"")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("error"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("code"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"'")])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v("f'Name: \"")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("error"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"'")])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v("f'Tags: \"")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("error"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tags"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"'")])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v("f'Note: \"")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("error"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("note"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"'")])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v("f'Message: \"")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("error"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("message"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"'")])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v("f'Description: \"")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("error"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"'")])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("pre",[s("code",[t._v('Code: "duplicate-header"\nName: "Duplicate Header"\nTags: "[\'#head\', \'#structure\']"\nNote: "at position "2""\nMessage: "Header "name" in field at position "3" is duplicated to header in another field: at position "2""\nDescription: "Two columns in the header row have the same value. Column names should be unique."\n')])]),t._v(" "),s("p",[t._v("Above, we have listed universal error properties. Depending on the type of an error there can be additional ones. For example, for our "),s("code",[t._v("duplicate-header")]),t._v(" error:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" validate\n\nreport "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data/capital-invalid.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pick_errors"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'duplicate-header'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nerror "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" report"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("error "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# it's only available for 1 table / 1 error sitution")]),t._v("\npprint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("error"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("pre",[s("code",[t._v("{'cell': 'name',\n 'cells': ['id', 'name', 'name'],\n 'code': 'duplicate-header',\n 'description': 'Two columns in the header row have the same value. Column '\n                'names should be unique.',\n 'fieldName': 'name2',\n 'fieldNumber': 3,\n 'fieldPosition': 3,\n 'message': 'Header \"name\" in field at position \"3\" is duplicated to header in '\n            'another field: at position \"2\"',\n 'name': 'Duplicate Header',\n 'note': 'at position \"2\"',\n 'tags': ['#head', '#structure']}\n")])]),t._v(" "),s("p",[t._v("Please explore “Errors Reference” to learn about all the available errors and their properties.")]),t._v(" "),s("h2",{attrs:{id:"errors-options"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#errors-options"}},[t._v("#")]),t._v(" Errors Options")]),t._v(" "),s("p",[t._v("We have already seen a few mentions of error options like "),s("code",[t._v("pick_errors")]),t._v(". Let’s take a look at all of them. These options are similiar to the "),s("code",[t._v("extract")]),t._v("'s counterparts for fields and rows.")]),t._v(" "),s("h3",{attrs:{id:"pick-skip-errors"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#pick-skip-errors"}},[t._v("#")]),t._v(" Pick/Skip Errors")]),t._v(" "),s("p",[t._v("We can pick or skip errors providing a list of error codes. For example:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" validate\n\nreport1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data/capital-invalid.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pick_errors"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'duplicate-header'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nreport2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data/capital-invalid.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" skip_errors"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'duplicate-header'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("report1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'rowPosition'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'fieldPosition'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'code'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("report2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'rowPosition'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'fieldPosition'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'code'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("pre",[s("code",[t._v("[[None, 3, 'duplicate-header']]\n[[10, 3, 'missing-cell'],\n [11, None, 'blank-row'],\n [12, 4, 'extra-cell'],\n [12, 1, 'type-error']]\n")])]),t._v(" "),s("p",[t._v("It’s also possible to use error tags (for more information please consult with “Errors Reference”):")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" validate\n\nreport1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data/capital-invalid.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pick_errors"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'#head'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nreport2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data/capital-invalid.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" skip_errors"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'#body'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("report1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'rowPosition'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'fieldPosition'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'code'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("report2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'rowPosition'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'fieldPosition'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'code'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("pre",[s("code",[t._v("[[None, 3, 'duplicate-header']]\n[[None, 3, 'duplicate-header']]\n")])]),t._v(" "),s("h3",{attrs:{id:"limit-errors"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#limit-errors"}},[t._v("#")]),t._v(" Limit Errors")]),t._v(" "),s("p",[t._v("This option is self-explanatory and can be used when you need to “fail fast” or get a limited amount of errors:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" validate\n\nreport "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data/capital-invalid.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" limit_errors"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("report"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'rowPosition'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'fieldPosition'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'code'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("pre",[s("code",[t._v("[[None, 3, 'duplicate-header']]\n")])]),t._v(" "),s("h2",{attrs:{id:"memory-options"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#memory-options"}},[t._v("#")]),t._v(" Memory Options")]),t._v(" "),s("p",[t._v("Frictionless is a streaming engine; usually it’s possible to validate terrabytes of data with basically O(1) memory consumption. For some validation, it’s not the case because Frctionless needs to buffer some cells e.g. to checks uniqueness. Here memory management can be handy.")]),t._v(" "),s("h3",{attrs:{id:"limit-memory"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#limit-memory"}},[t._v("#")]),t._v(" Limit Memory")]),t._v(" "),s("p",[t._v("Default memory limit is 1000MB. You can adjust it based on your exact use case. For example, if you’re running Frictionless as an API server you might reduce the memory usage. If a validation hits the limit it will not raise of fail - it will return a report with a task error:")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" validate\n\nsource "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lambda")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("integer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" integer "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("100000000")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nschema "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fields"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"integer"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"type"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"integer"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"primaryKey"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"integer"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\nreport "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" headers"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" schema"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("schema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" limit_memory"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("report"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"code"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"note"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [['task-error', 'exceeded memory limit \"50MB\"']]")]),t._v("\n")])])]),s("h2",{attrs:{id:"checks-options"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#checks-options"}},[t._v("#")]),t._v(" Checks Options")]),t._v(" "),s("p",[t._v("Ther are two check options: "),s("code",[t._v("checksum")]),t._v(" and "),s("code",[t._v("extra_checks")]),t._v(". The first allows to stricten a baseline validation white the latter is used to enforce additional checks.")]),t._v(" "),s("h3",{attrs:{id:"checksum"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#checksum"}},[t._v("#")]),t._v(" Checksum")]),t._v(" "),s("p",[t._v("We can provide a hash string, the amount of bytes, and the amount of rows. Frictionless will ensure as a part of a validation that the actual values match the expected ones. Let’s show for the hash:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" validate\n\nreport "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data/capital-invalid.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" checksum"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'hash'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'bad'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pick_errors"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'#checksum'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("report"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"code"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"note"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("pre",[s("code",[t._v("[['checksum-error', 'expected hash in md5 is \"bad\" and actual is \"dcdeae358cfd50860c18d953e021f836\"']]\n")])]),t._v(" "),s("p",[t._v("The same can be show for the bytes and rows:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" validate\n\nreport "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data/capital-invalid.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" checksum"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'bytes'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'rows'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pick_errors"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'#checksum'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("report"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"code"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"note"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("pre",[s("code",[t._v("[['checksum-error', 'expected bytes count is \"10\" and actual is \"171\"'],\n ['checksum-error', 'expected rows count is \"10\" and actual is \"11\"']]\n")])]),t._v(" "),s("h3",{attrs:{id:"extra-checks"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#extra-checks"}},[t._v("#")]),t._v(" Extra Checks")]),t._v(" "),s("p",[t._v("It’s possible to provide a list of extra checks where individual checks are in the form of:")]),t._v(" "),s("ul",[s("li",[t._v("a string: "),s("code",[t._v("check-name")])]),t._v(" "),s("li",[t._v("a list: "),s("code",[t._v("['check-name', {'option1': 'value1'}]")])])]),t._v(" "),s("p",[t._v("It’s also possible to use a "),s("code",[t._v("Check")]),t._v(" subclass instead of name which will be shown in the “Custom Checks” section. Let’s have a loot at an example:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" validate\n\nreport "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data/capital-invalid.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" extra_checks"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'sequential-value'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'fieldName'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'id'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("report"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"rowPosition"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fieldPosition"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"code"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"note"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("pre",[s("code",[t._v("[[None, 3, 'duplicate-header', 'at position \"2\"'],\n [10, 3, 'missing-cell', ''],\n [10, 1, 'sequential-value', 'the value is not sequential'],\n [11, None, 'blank-row', ''],\n [12, 4, 'extra-cell', ''],\n [12, 1, 'type-error', 'type is \"integer/default\"']]\n")])]),t._v(" "),s("p",[t._v("See the sections below for a list of available checks.")]),t._v(" "),s("h2",{attrs:{id:"baseline-check"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#baseline-check"}},[t._v("#")]),t._v(" Baseline Check")]),t._v(" "),s("p",[t._v("By default, Frictionless runs only the Baseline Check but includes vairous smaller checks revealing a great deal of tabular errors. There is a "),s("code",[t._v("report.tables[].scope")]),t._v(" property to check what exact errors it have been checked for:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" validate\n\nreport "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data/capital-invalid.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("report"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("table"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scope"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("pre",[s("code",[t._v("['dialect-error',\n 'schema-error',\n 'field-error',\n 'extra-header',\n 'missing-header',\n 'blank-header',\n 'duplicate-header',\n 'non-matching-header',\n 'extra-cell',\n 'missing-cell',\n 'blank-row',\n 'type-error',\n 'constraint-error',\n 'unique-error',\n 'primary-key-error',\n 'foreign-key-error',\n 'checksum-error']\n")])]),t._v(" "),s("h2",{attrs:{id:"heuristic-checks"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#heuristic-checks"}},[t._v("#")]),t._v(" Heuristic Checks")]),t._v(" "),s("p",[t._v("There is a group of checks that indicate probable errors. You need to use the "),s("code",[t._v("extra_checks")]),t._v(" argument of the "),s("code",[t._v("validate")]),t._v(" function to active one or more of these checks.")]),t._v(" "),s("h3",{attrs:{id:"duplicate-row"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#duplicate-row"}},[t._v("#")]),t._v(" Duplicate Row")]),t._v(" "),s("p",[t._v("This check is self-explanatory. You need to take into account that checking for duplicate rows can lean to high memory consumption on big files. Here is an example:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" validate\n\nsource "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'header\\nvalue\\nvalue'")]),t._v("\nreport "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" scheme"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'text'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" extra_checks"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'duplicate-row'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("report"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'code'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'message'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("pre",[s("code",[t._v("[['duplicate-row',\n  'Row at position 3 is duplicated: the same as row at position \"2\"']]\n")])]),t._v(" "),s("h3",{attrs:{id:"deviated-value"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#deviated-value"}},[t._v("#")]),t._v(" Deviated Value")]),t._v(" "),s("p",[t._v("This check uses the Python’s builtin "),s("code",[t._v("statistics")]),t._v(" module to check a field’s data for deviations. By default, deviated values are outside of the average ± three standard deviations. Take a look at the "),s("a",{attrs:{href:"https://github.com/frictionlessdata/frictionless-py/blob/master/docs/target/api-reference/README.md#deviatedvaluecheck",target:"_blank",rel:"noopener noreferrer"}},[t._v("API Reference"),s("OutboundLink")],1),t._v(" for more details about available options and default values. The exact algorithm can be found "),s("a",{attrs:{href:"https://github.com/frictionlessdata/frictionless-py/blob/7ae8bae9a9197adbfe443233a6bad8a94e065ece/frictionless/checks/heuristic.py#L94",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),s("OutboundLink")],1),t._v(". For example:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" validate\n\n    source "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"temperature"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    report "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" extra_checks"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"deviated-value"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fieldName"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"temperature"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    pprint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("report"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"code"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"message"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),s("pre",[s("code",[t._v("[['deviated-value',\n  'There is a possible error because the value is deviated: value \"1000\" in '\n  'row at position \"10\" and field \"temperature\" is deviated \"[-809.88, '\n  '995.52]\"']]\n")])]),t._v(" "),s("h3",{attrs:{id:"truncated-value"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#truncated-value"}},[t._v("#")]),t._v(" Truncated Value")]),t._v(" "),s("p",[t._v("Sometime during the explort from a database or another storage, data values can be truncated. This check tries to detect it. Let’s explore some trunctation indicators:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" validate\n\nsource "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"int"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"str"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("255")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("32767")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"good"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2147483647")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nreport "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" extra_checks"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"truncated-value"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("report"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"code"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"message"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("pre",[s("code",[t._v("[['truncated-value',\n  'The cell '\n  'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa '\n  'in row at position 2 and field int at position 1 has an error: value  is '\n  'probably truncated'],\n ['truncated-value',\n  'The cell 32767 in row at position 2 and field str at position 2 has an '\n  'error: value  is probably truncated'],\n ['truncated-value',\n  'The cell 2147483647 in row at position 3 and field str at position 2 has an '\n  'error: value  is probably truncated']]\n")])]),t._v(" "),s("h2",{attrs:{id:"regulation-checks"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#regulation-checks"}},[t._v("#")]),t._v(" Regulation Checks")]),t._v(" "),s("p",[t._v("In countrary to heuristic checks, regulation checks gives you an ability to provide additional rules for your data. Use the "),s("code",[t._v("extra_checks")]),t._v(" argument of the "),s("code",[t._v("validate")]),t._v(" function to active one or more of these checks.")]),t._v(" "),s("h3",{attrs:{id:"blacklisted-value"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#blacklisted-value"}},[t._v("#")]),t._v(" Blacklisted Value")]),t._v(" "),s("p",[t._v("This check ensures that some field doesn’t have any blacklisted values. For example:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" validate\n\nsource "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'header\\nvalue1\\nvalue2'")]),t._v("\nextra_checks "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'blacklisted-value'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'fieldName'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'header'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'blacklist'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'value2'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nreport "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" scheme"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'text'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" extra_checks"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("extra_checks"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("report"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'code'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'message'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("pre",[s("code",[t._v("[['blacklisted-value',\n  'The cell value2 in row at position 3 and field header at position 1 has an '\n  'error: blacklisted values are \"[\\'value2\\']\"']]\n")])]),t._v(" "),s("h3",{attrs:{id:"sequential-value"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#sequential-value"}},[t._v("#")]),t._v(" Sequential Value")]),t._v(" "),s("p",[t._v("This check gives us an opportunity to validate sequential fields like primary keys or other similiar data. It doesn’t need to start from 0 or 1. We’re providing a field name:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" validate\n\nsource "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'header\\n2\\n3\\n5'")]),t._v("\nextra_checks "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'sequential-value'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'fieldName'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'header'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nreport "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" scheme"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'text'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" extra_checks"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("extra_checks"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("report"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'code'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'message'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("pre",[s("code",[t._v("[['sequential-value',\n  'The cell 5 in row at position 4 and field header at position 1 has an '\n  'error: the value is not sequential']]\n")])]),t._v(" "),s("h3",{attrs:{id:"row-constraint"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#row-constraint"}},[t._v("#")]),t._v(" Row Constraint")]),t._v(" "),s("p",[t._v("This checks is the most powerful one as it uses the external "),s("code",[t._v("simpleeval")]),t._v(" package allowing to evalute arbitrary python expressions on data rows. Let’s show on an example:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" validate\n\nsource "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"row"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"salary"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bonus"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("200")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2500")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("500")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1300")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("500")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5000")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nextra_checks"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"row-constraint"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"constraint"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"salary == bonus * 5"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nreport "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" extra_checks"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("extra_checks"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("report"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"code"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"message"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("pre",[s("code",[t._v("[['row-constraint',\n  'The row at position 4 has an error: the row constraint to conform is '\n  '\"salary == bonus * 5\"']]\n")])]),t._v(" "),s("h2",{attrs:{id:"custom-checks"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#custom-checks"}},[t._v("#")]),t._v(" Custom Checks")]),t._v(" "),s("p",[t._v("There are many cases when built-in Frictionless’ checks are not enough. It can be a business logic rule or specific quality requirement to the data. With Frictionless it’s very easy to use your own custom checks. Let’s see on an example:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" errors"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Check\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Create check")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ForbidNumber")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Check"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("validate_row")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" row"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" row"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'header'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'number'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n          note "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"number ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'number'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(' is forbidden!"')])]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("yield")]),t._v(" errors"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("CellError"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_row"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("row"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" note"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("note"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" field_name"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'header'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Validate table")]),t._v("\nsource "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'header\\n1\\n2\\n3'")]),t._v("\nextra_checks"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ForbidNumber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'number'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nreport "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" validate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  scheme"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'text'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" extra_checks"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("extra_checks"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("report"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"rowPosition"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fieldPosition"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"code"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"note"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("pre",[s("code",[t._v("[[3, 1, 'cell-error', 'number 2 is forbidden!']]\n")])]),t._v(" "),s("p",[t._v("Usualy, it also makes sense to create a custom error for your custom check. The Check class provides other useful methods like "),s("code",[t._v("validate_header")]),t._v(" etc. Please read “API Reference” to learn it in details.")])])}),[],!1,null,null,null);a.default=e.exports}}]);