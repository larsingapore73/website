(window.webpackJsonp=window.webpackJsonp||[]).push([[133],{494:function(t,a,e){"use strict";e.r(a);var s=e(1),n=Object(s.a)({},(function(){var t=this,a=t.$createElement,e=t._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"describing-data"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#describing-data"}},[t._v("#")]),t._v(" Describing Data")]),t._v(" "),e("p",[t._v("What does “describing data” mean?")]),t._v(" "),e("p",[t._v("Frictionless is a project based on the "),e("a",{attrs:{href:"https://specs.frictionlessdata.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Frictionless Data Specifications"),e("OutboundLink")],1),t._v(". It’s a set of patterns for creating metadata, including Data Package (for datasets), Data Resource (for files), and Table Schema (for tables).")]),t._v(" "),e("p",[t._v("In other words, “describing data” means creating metadata for your data files. The reason for having metadata is simple: usually, data files themselves are not capable of providing enough information. For example, if you have a data table in a CSV format, it misses a few critical pieces of information:")]),t._v(" "),e("ul",[e("li",[t._v("meaning of the fields e.g., what the "),e("code",[t._v("size")]),t._v(" field means; is it clothes size or file size")]),t._v(" "),e("li",[t._v("data types information e.g., is this field a string or an integer")]),t._v(" "),e("li",[t._v("data constraints e.g., the minimum temperature for your measurements")]),t._v(" "),e("li",[t._v("data relations e.g., identifiers connection")]),t._v(" "),e("li",[t._v("and others")])]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v("! pip install frictionless\n")])])]),e("p",[t._v("For a dataset, there is even more information that can be provided like general dataset purpose, information about data sources, list of authors, and many more. Of course, when there are many tabular files, relational rules can be very important. Usually, there are foreign keys ensuring the integrity of the dataset; for example, there is some reference table containing country names and other tables using it as a reference. Data in this form is called “normalized data” and it occurs very often in scientific and another kind of research.")]),t._v(" "),e("p",[t._v("Having a general understanding of what is “data describing”, we can now articulate why it’s important:")]),t._v(" "),e("ul",[e("li",[e("strong",[t._v("data validation")]),t._v("; metadata helps to reveal problems in your data on the early stages of your workflow")]),t._v(" "),e("li",[e("strong",[t._v("data publication")]),t._v("; metadata provides additional information that your data can’t include")])]),t._v(" "),e("p",[t._v("There are not the only two pros of having metadata but they are two the most important. Please continue reading to learn how Frictionless helps to achieve these advantages describing your data.")]),t._v(" "),e("h2",{attrs:{id:"describe-functions"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#describe-functions"}},[t._v("#")]),t._v(" Describe Functions")]),t._v(" "),e("p",[t._v("The "),e("code",[t._v("describe")]),t._v(" functions are the main tool for data describing. In many cases, this high-level interface is enough for data exploration and other needs.")]),t._v(" "),e("p",[t._v("The frictionless framework provides 4 different "),e("code",[t._v("describe")]),t._v(" functions in Python:")]),t._v(" "),e("ul",[e("li",[e("code",[t._v("describe")]),t._v(": it will detect the source type and return Data Resource or Data Package metadata")]),t._v(" "),e("li",[e("code",[t._v("describe_schema")]),t._v(": it will always return Table Schema metadata")]),t._v(" "),e("li",[e("code",[t._v("describe_resource")]),t._v(": it will always return Data Resource metadata")]),t._v(" "),e("li",[e("code",[t._v("describe_package")]),t._v(": it will always return Data Package metadata")])]),t._v(" "),e("p",[t._v("In command-line, there is only 1 command but there is a flag to adjust the behavior:")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v("! frictionless describe\n! frictionless describe --source-type schema\n! frictionless describe --source-type resource\n! frictionless describe --source-type package\n")])])]),e("p",[t._v("For example, if we want a Data Package descriptor for a single file:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! frictionless describe data"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("table"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("csv "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("source"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),t._v(" package\n")])])]),e("pre",[e("code",[t._v("---\nmetadata: data/table.csv\n---\n\nprofile: data-package\nresources:\n  - compression: 'no'\n    compressionPath: ''\n    control:\n      newline: ''\n    dialect: {}\n    encoding: utf-8\n    format: csv\n    hashing: md5\n    name: table\n    path: data/table.csv\n    profile: tabular-data-resource\n    query: {}\n    schema:\n      fields:\n        - name: id\n          type: integer\n        - name: name\n          type: string\n    scheme: file\n    stats:\n      bytes: 30\n      fields: 2\n      hash: 6c2c61dd9b0e9c6876139a449ed87933\n      rows: 2\n")])]),t._v(" "),e("h3",{attrs:{id:"describing-schema"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#describing-schema"}},[t._v("#")]),t._v(" Describing Schema")]),t._v(" "),e("p",[t._v("Table Schema is a specification for providing a “schema” (similar to a database schema) for tabular data. This information includes the expected type of each value in a column (“string”, “number”, “date”, etc.), constraints on the value (“this string can only be at most 10 characters long”), and the expected format of the data (“this field should only contain strings that look like email addresses”). Table Schema can also specify relations between tables.")]),t._v(" "),e("p",[t._v("We’re going to use this file for this section examples. For this guide, we use solely CSV files because of their demonstrativeness but in-general Frictionless can handle Excel, JSON, SQL, and many other formats:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! cat data"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("country"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.")]),t._v("csv\n")])])]),e("pre",[e("code",[t._v("id,neighbor_id,name,population\n1,,Britain,67\n2,3,France,67\n3,2,Germany,83\n4,5,Italy,60\n5,4,Spain,47\n")])]),t._v(" "),e("p",[t._v("Let’s get Table Schema using Frictionless framework:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" describe_schema\n\nschema "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" describe_schema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"data/country-1.csv"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nschema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_yaml"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tmp/country.schema-simple.yaml"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("The high-level functions of Frictionless operate on dataset and resource levels so we have to use Python a little of Python programming to get schema information. Below we will show how to use a command-line interface for similar tasks.")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! cat tmp"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("country"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("simple"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yaml\n")])])]),e("pre",[e("code",[t._v("fields:\n  - name: id\n    type: integer\n  - name: neighbor_id\n    type: integer\n  - name: name\n    type: string\n  - name: population\n    type: integer\n")])]),t._v(" "),e("p",[t._v("As we can see, we were able to get infer basic metadata of our data file but describing data doesn’t end here, we can  provide additional information we discussed earlier:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" describe_schema\n\nschema "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" describe_schema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"data/country-1.csv"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nschema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_field"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("title "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Identifier"')]),t._v("\nschema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_field"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"neighbor_id"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("title "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Identifier of the neighbor"')]),t._v("\nschema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_field"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("title "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Name of the country"')]),t._v("\nschema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_field"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"population"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("title "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Population"')]),t._v("\nschema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_field"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"population"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("description "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"According to the year 2020\'s data"')]),t._v("\nschema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_field"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"population"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("constraints"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"minimum"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\nschema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreign_keys"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fields"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"neighbor_id"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"reference"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"resource"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fields"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nschema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_yaml"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tmp/country.schema.yaml"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("Let’s break it down:")]),t._v(" "),e("ul",[e("li",[t._v("we added a title for all the fields")]),t._v(" "),e("li",[t._v("we added a description to the “Population” field; the year information can be critical to interpret the data")]),t._v(" "),e("li",[t._v("we set a constraint to the “Population” field because it can’t be less than 0")]),t._v(" "),e("li",[t._v("we added a foreign key saying that “Identifier of the neighbor” should present in the “Identifier” field")])]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! cat tmp"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("country"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yaml\n")])])]),e("pre",[e("code",[t._v("fields:\n  - name: id\n    title: Identifier\n    type: integer\n  - name: neighbor_id\n    title: Identifier of the neighbor\n    type: integer\n  - name: name\n    title: Name of the country\n    type: string\n  - constraints:\n      minimum: 0\n    description: According to the year 2020's data\n    name: population\n    title: Population\n    type: integer\nforeignKeys:\n  - fields:\n      - neighbor_id\n    reference:\n      fields:\n        - id\n      resource: ''\n")])]),t._v(" "),e("p",[t._v("Later we’re going to show how to use the schema we created to ensure the validity of your data; in the next few sections, we will focus on Data Resource and Data Package metadata.")]),t._v(" "),e("p",[t._v("To continue learning about table schemas please read:")]),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"https://specs.frictionlessdata.io/table-schema/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Table Schema Spec"),e("OutboundLink")],1)]),t._v(" "),e("li",[t._v("API Reference: Schema")])]),t._v(" "),e("h3",{attrs:{id:"describing-resource"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#describing-resource"}},[t._v("#")]),t._v(" Describing Resource")]),t._v(" "),e("p",[t._v("The Data Resource format describes a data resource such as an individual file or table."),e("br"),t._v("\nThe essence of a Data Resource is a locator for the data it describes."),e("br"),t._v("\nA range of other properties can be declared to provide a richer set of metadata.")]),t._v(" "),e("p",[t._v("For this section, we will use the file that is slightly more complex to handle. For some reason, cells are separated by the “;” char and there is a comment on the top:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! cat data"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("country"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.")]),t._v("csv\n")])])]),e("pre",[e("code",[t._v("# Author: the scientist\nid;neighbor_id;name;population\n1;;Britain;67\n2;3;France;67\n3;2;Germany;83\n4;5;Italy;60\n5;4;Spain;47\n")])]),t._v(" "),e("p",[t._v("Let’s describe it this time using the command-line interface:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! frictionless describe data"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("country"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.")]),t._v("csv\n")])])]),e("pre",[e("code",[t._v("---\nmetadata: data/country-2.csv\n---\n\ncompression: 'no'\ncompressionPath: ''\ncontrol:\n  newline: ''\ndialect: {}\nencoding: utf-8\nformat: csv\nhashing: md5\nname: country-2\npath: data/country-2.csv\nprofile: tabular-data-resource\nquery: {}\nschema:\n  fields:\n    - name: '# Author: the scientist'\n      type: string\nscheme: file\nstats:\n  bytes: 124\n  fields: 1\n  hash: 88e1901235a8cf35da4d28a1cdf415e5\n  rows: 6\n")])]),t._v(" "),e("p",[t._v("OK, that’s clearly wrong. As we have seen in the “Introductory Guide” Frictionless is capable of inferring some complicated cases’ metadata but our table is too weird for it. We need to program it:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" describe_resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Schema\n\nresource "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" describe_resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"data/country-2.csv"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nresource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dialect"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("header_rows "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nresource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dialect"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("delimiter "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('";"')]),t._v("\nresource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Schema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tmp/country.schema.yaml"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nresource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_yaml"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tmp/country.resource.yaml"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("So what we are doing here:")]),t._v(" "),e("ul",[e("li",[t._v("we set header rows to be row number 2; as humans, we can easily see it")]),t._v(" "),e("li",[t._v("we set CSV Delimiter to be “;”; this file in not really usual CSV for some reason")]),t._v(" "),e("li",[t._v("we reuse the schema we created earlier as the data has the same structure and meaning")])]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! cat tmp"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("country"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yaml\n")])])]),e("pre",[e("code",[t._v("compression: 'no'\ncompressionPath: ''\ncontrol:\n  newline: ''\ndialect:\n  delimiter: ;\n  headerRows:\n    - 2\nencoding: utf-8\nformat: csv\nhashing: md5\nname: country-2\npath: data/country-2.csv\nprofile: tabular-data-resource\nquery: {}\nschema:\n  fields:\n    - name: id\n      title: Identifier\n      type: integer\n    - name: neighbor_id\n      title: Identifier of the neighbor\n      type: integer\n    - name: name\n      title: Name of the country\n      type: string\n    - constraints:\n        minimum: 0\n      description: According to the year 2020's data\n      name: population\n      title: Population\n      type: integer\n  foreignKeys:\n    - fields:\n        - neighbor_id\n      reference:\n        fields:\n          - id\n        resource: ''\nscheme: file\nstats:\n  bytes: 124\n  fields: 1\n  hash: 88e1901235a8cf35da4d28a1cdf415e5\n  rows: 6\n")])]),t._v(" "),e("p",[t._v("Our resource metadata includes the schema metadata we created earlier but also it has:")]),t._v(" "),e("ul",[e("li",[t._v("general information about the file’s schema, format, and compression")]),t._v(" "),e("li",[t._v("information about CSV Dialect helping software understand how to read it")]),t._v(" "),e("li",[t._v("checksum information as though hash, bytes, and rows")])]),t._v(" "),e("p",[t._v("But the most important difference is that resource metadata contains the "),e("code",[t._v("path")]),t._v(" property. It conceptually distinct Data Resource specification from Table Schema specification because while a Table Schema descriptor can describe a class of data files, a Data Resource descriptor describes the only one exact data file, "),e("code",[t._v("data/country-2.csv")]),t._v(" in our case.")]),t._v(" "),e("p",[t._v("Using programming terminology we could say that:")]),t._v(" "),e("ul",[e("li",[t._v("Table Schema descriptor is abstract (for a class of files)")]),t._v(" "),e("li",[t._v("Data Resource descriptor is concrete (for an individual file)")])]),t._v(" "),e("p",[t._v("We will show the practical difference in the “Using Metadata” section but in the next section, we will overview the Data Package specification.")]),t._v(" "),e("p",[t._v("To continue learning about data resources please read:")]),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"https://specs.frictionlessdata.io/data-resource/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Data Resource Spec"),e("OutboundLink")],1)]),t._v(" "),e("li",[t._v("API Reference: Resource")])]),t._v(" "),e("h3",{attrs:{id:"describing-package"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#describing-package"}},[t._v("#")]),t._v(" Describing Package")]),t._v(" "),e("p",[t._v("A Data Package consists of:")]),t._v(" "),e("ul",[e("li",[t._v("Metadata that describes the structure and contents of the package")]),t._v(" "),e("li",[t._v("Resources such as data files that form the contents of the package"),e("br"),t._v("\nThe Data Package metadata is stored in a “descriptor”. This descriptor is what makes a collection of data a Data Package. The structure of this descriptor is the main content of the specification below.")])]),t._v(" "),e("p",[t._v("In addition to this descriptor, a data package will include other resources such as data files. The Data Package specification does NOT impose any requirements on their form or structure and can, therefore, be used for packaging any kind of data.")]),t._v(" "),e("p",[t._v("The data included in the package may be provided as:")]),t._v(" "),e("ul",[e("li",[t._v("Files bundled locally with the package descriptor")]),t._v(" "),e("li",[t._v("Remote resources, referenced by URL")]),t._v(" "),e("li",[t._v("“Inline” data (see below) which is included directly in the descriptor")])]),t._v(" "),e("p",[t._v("For this section, we will use the following files:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! cat data"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("country"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.")]),t._v("csv\n")])])]),e("pre",[e("code",[t._v("id,capital_id,name,population\n1,1,Britain,67\n2,3,France,67\n3,2,Germany,83\n4,5,Italy,60\n5,4,Spain,47\n")])]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! cat data"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("capital"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.")]),t._v("csv\n")])])]),e("pre",[e("code",[t._v("id,name\n1,London\n2,Berlin\n3,Paris\n4,Madrid\n5,Rome\n")])]),t._v(" "),e("p",[t._v("First of all, let’s describe our package using the command-line interface. We did it before for a resource but now we’re going to use a glob pattern to indicate that there are multiple files:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! frictionless describe data"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.")]),t._v("csv\n")])])]),e("pre",[e("code",[t._v("---\nmetadata: data/capital-3.csv data/country-3.csv\n---\n\nprofile: data-package\nresources:\n  - compression: 'no'\n    compressionPath: ''\n    control:\n      newline: ''\n    dialect: {}\n    encoding: utf-8\n    format: csv\n    hashing: md5\n    name: capital-3\n    path: data/capital-3.csv\n    profile: tabular-data-resource\n    query: {}\n    schema:\n      fields:\n        - name: id\n          type: integer\n        - name: name\n          type: string\n    scheme: file\n    stats:\n      bytes: 50\n      fields: 2\n      hash: e7b6592a0a4356ba834e4bf1c8e8c7f8\n      rows: 5\n  - compression: 'no'\n    compressionPath: ''\n    control:\n      newline: ''\n    dialect: {}\n    encoding: utf-8\n    format: csv\n    hashing: md5\n    name: country-3\n    path: data/country-3.csv\n    profile: tabular-data-resource\n    query: {}\n    schema:\n      fields:\n        - name: id\n          type: integer\n        - name: capital_id\n          type: integer\n        - name: name\n          type: string\n        - name: population\n          type: integer\n    scheme: file\n    stats:\n      bytes: 100\n      fields: 4\n      hash: c0558b91523683483f86f63346d06d81\n      rows: 5\n")])]),t._v(" "),e("p",[t._v("We have already learned about many concepts that are reflected in this metadata. We can see resources, schemas, fields, and other familiar entities. The difference is that this descriptor has information about multiple files which is the most popular way of sharing data - in datasets. Very often you have not only one data file but also additional data files, some textual documents e.g. PDF, and others. To package all of these files with the corresponding metadata we use data packages.")]),t._v(" "),e("p",[t._v("Following the already familiar to the guide’s reader pattern, we add some additional metadata:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" describe_package\n\npackage "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" describe_package"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"data/*-3.csv"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npackage"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("title "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Countries and their capitals"')]),t._v("\npackage"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("description "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"The data was collected as a research project"')]),t._v("\npackage"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"country-3"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"country"')]),t._v("\npackage"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"capital-3"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"capital"')]),t._v("\npackage"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"country"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreign_keys"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fields"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"capital_id"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"reference"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"resource"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"capital"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fields"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npackage"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_yaml"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tmp/country.package.yaml"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("In this case, we add a relation between different files connecting "),e("code",[t._v("id")]),t._v(" and "),e("code",[t._v("capital_id")]),t._v(". Also, we provide dataset-level metadata to share with the purpose of this dataset. We haven’t added individual fields’ titles and description but it can be done as it was shown in the “Table Schema” section.")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! cat tmp"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("country"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("package"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yaml\n")])])]),e("pre",[e("code",[t._v("description: The data was collected as a research project\nprofile: data-package\nresources:\n  - compression: 'no'\n    compressionPath: ''\n    control:\n      newline: ''\n    dialect: {}\n    encoding: utf-8\n    format: csv\n    hashing: md5\n    name: capital\n    path: data/capital-3.csv\n    profile: tabular-data-resource\n    query: {}\n    schema:\n      fields:\n        - name: id\n          type: integer\n        - name: name\n          type: string\n    scheme: file\n    stats:\n      bytes: 50\n      fields: 2\n      hash: e7b6592a0a4356ba834e4bf1c8e8c7f8\n      rows: 5\n  - compression: 'no'\n    compressionPath: ''\n    control:\n      newline: ''\n    dialect: {}\n    encoding: utf-8\n    format: csv\n    hashing: md5\n    name: country\n    path: data/country-3.csv\n    profile: tabular-data-resource\n    query: {}\n    schema:\n      fields:\n        - name: id\n          type: integer\n        - name: capital_id\n          type: integer\n        - name: name\n          type: string\n        - name: population\n          type: integer\n      foreignKeys:\n        - fields:\n            - capital_id\n          reference:\n            fields:\n              - id\n            resource: capital\n    scheme: file\n    stats:\n      bytes: 100\n      fields: 4\n      hash: c0558b91523683483f86f63346d06d81\n      rows: 5\ntitle: Countries and their capitals\n")])]),t._v(" "),e("p",[t._v("The main role of the Data Package descriptor is describing a dataset; as we can see, it includes previously shown descriptors as though "),e("code",[t._v("schema")]),t._v(", "),e("code",[t._v("dialect")]),t._v(", and "),e("code",[t._v("resource")]),t._v(". But it’s a mistake to think then that Data Package is the least important specification; actually, it completes the Frictionless Data suite making possible sharing and validating not only individual files but complete datasets.")]),t._v(" "),e("p",[t._v("To continue learning about data resources please read:")]),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"https://specs.frictionlessdata.io/data-package/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Data Package Spec"),e("OutboundLink")],1)]),t._v(" "),e("li",[t._v("API Reference: Package")])]),t._v(" "),e("h2",{attrs:{id:"description-options"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#description-options"}},[t._v("#")]),t._v(" Description Options")]),t._v(" "),e("p",[t._v("The "),e("code",[t._v("describe")]),t._v(" functions above share the only one common argument:")]),t._v(" "),e("ul",[e("li",[e("code",[t._v("expand")]),t._v(": whether to expand output metadata or not (see “Expanding Metadata”)")])]),t._v(" "),e("h3",{attrs:{id:"package"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#package"}},[t._v("#")]),t._v(" Package")]),t._v(" "),e("p",[t._v("The "),e("code",[t._v("describe_package")]),t._v(" doesn’t accept any additional options.")]),t._v(" "),e("h2",{attrs:{id:"resource"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#resource"}},[t._v("#")]),t._v(" Resource")]),t._v(" "),e("p",[t._v("With the "),e("code",[t._v("describe_resource")]),t._v(" function you can use as options:")]),t._v(" "),e("ul",[e("li",[t._v("File Details (see “Extracting Data”)")]),t._v(" "),e("li",[t._v("File Control (see “Extracting Data”)")]),t._v(" "),e("li",[t._v("Table Dialect (see “Extracting Data”)")]),t._v(" "),e("li",[t._v("Table Query (see “Extracting Data”)")]),t._v(" "),e("li",[t._v("Header Options (see “Extracting Data”)")]),t._v(" "),e("li",[t._v("Infer Options")])]),t._v(" "),e("h2",{attrs:{id:"metadata-purpose"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#metadata-purpose"}},[t._v("#")]),t._v(" Metadata Purpose")]),t._v(" "),e("p",[t._v("This documentation contains a great deal of information on how to use metadata and why it’s vital for your data. In this article, we’re going to provide a quick example based on the “Data Resource” section but please read other documents to get the full picture.")]),t._v(" "),e("p",[t._v("Let’s get back to this exotic data table:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! cat data"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("country"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.")]),t._v("csv\n")])])]),e("pre",[e("code",[t._v("# Author: the scientist\nid;neighbor_id;name;population\n1;;Britain;67\n2;3;France;67\n3;2;Germany;83\n4;5;Italy;60\n5;4;Spain;47\n")])]),t._v(" "),e("p",[t._v("As we tried before, by default Frictionless can’t properly describe this file so we got something like:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! frictionless describe data"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("country"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.")]),t._v("csv\n")])])]),e("pre",[e("code",[t._v("---\nmetadata: data/country-2.csv\n---\n\ncompression: 'no'\ncompressionPath: ''\ncontrol:\n  newline: ''\ndialect: {}\nencoding: utf-8\nformat: csv\nhashing: md5\nname: country-2\npath: data/country-2.csv\nprofile: tabular-data-resource\nquery: {}\nschema:\n  fields:\n    - name: '# Author: the scientist'\n      type: string\nscheme: file\nstats:\n  bytes: 124\n  fields: 1\n  hash: 88e1901235a8cf35da4d28a1cdf415e5\n  rows: 6\n")])]),t._v(" "),e("p",[t._v("Trying to extract the data will fail the same way:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! frictionless extract data"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("country"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.")]),t._v("csv\n")])])]),e("pre",[e("code",[t._v("---\ndata: data/country-2.csv\n---\n\n==============================\n# Author: the scientist\n==============================\nid;neighbor_id;name;population\n1;;Britain;67\n2;3;France;67\n3;2;Germany;83\n4;5;Italy;60\n5;4;Spain;47\n==============================\n")])]),t._v(" "),e("p",[t._v("Basically, that’s a really important idea - with not metadata many software will not be able to even read this data file, furthermore, without metadata people can not understand the purpose of this data. Let’s now use the "),e("code",[t._v("country.resource.yaml")]),t._v(" the file we created in the “Data Resource” section:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! frictionless extract tmp"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("country"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yaml "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("basepath "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n")])])]),e("pre",[e("code",[t._v("---\ndata: tmp/country.resource.yaml\n---\n\n==  ===========  =======  ==========\nid  neighbor_id  name     population\n==  ===========  =======  ==========\n 1  None         Britain          67\n 2            3  France           67\n 3            2  Germany          83\n 4            5  Italy            60\n 5            4  Spain            47\n==  ===========  =======  ==========\n")])]),t._v(" "),e("p",[t._v("As we can see, it’s now fixed. The metadata we’d had saved the day. If we explore this data in Python we can discover that it also correct data types e.g. "),e("code",[t._v("id")]),t._v(" is Python’s integer not string. This fact will allow exporting and sharing this data without any fear.")]),t._v(" "),e("h2",{attrs:{id:"metadata-classes"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#metadata-classes"}},[t._v("#")]),t._v(" Metadata Classes")]),t._v(" "),e("p",[t._v("Frictionless has many classes that is derived from the "),e("code",[t._v("Metadata")]),t._v(" class. It means that all of them can be treated as a metadata object with getters and setters, "),e("code",[t._v("to_json")]),t._v(" and "),e("code",[t._v("to_yaml")]),t._v(" function, and other Metadata’s API. See “API Reference” for more information about these classes:")]),t._v(" "),e("ul",[e("li",[t._v("Package")]),t._v(" "),e("li",[t._v("Resource")]),t._v(" "),e("li",[t._v("Schema")]),t._v(" "),e("li",[t._v("Field")]),t._v(" "),e("li",[t._v("Control")]),t._v(" "),e("li",[t._v("Dialect")]),t._v(" "),e("li",[t._v("Query")]),t._v(" "),e("li",[t._v("Report")]),t._v(" "),e("li",[t._v("Pipeline")]),t._v(" "),e("li",[t._v("Error")]),t._v(" "),e("li",[t._v("etc")])]),t._v(" "),e("h2",{attrs:{id:"inferring-metadata"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#inferring-metadata"}},[t._v("#")]),t._v(" Inferring Metadata")]),t._v(" "),e("p",[t._v("Many Frictionless functions infer metadata under the hood as though "),e("code",[t._v("describe")]),t._v(", "),e("code",[t._v("extract")]),t._v(", and many more. On a lower-level, it’s possible to control this process. Let’s create a "),e("code",[t._v("Resource")]),t._v(".")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Resource\n\nresource "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"data/country-1.csv"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("pre",[e("code",[t._v("{'path': 'data/country-1.csv'}\n")])]),t._v(" "),e("p",[t._v("Frictionless always tries to be as explicit as possible. We didn’t provide any metadata except for "),e("code",[t._v("type")]),t._v(" so we got the expected result. But now, we’d like to "),e("code",[t._v("infer")]),t._v(" additional metadata:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("infer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("pre",[e("code",[t._v("{'compression': 'no',\n 'compressionPath': '',\n 'control': {'newline': ''},\n 'dialect': {},\n 'encoding': 'utf-8',\n 'format': 'csv',\n 'hashing': 'md5',\n 'name': 'country-1',\n 'path': 'data/country-1.csv',\n 'profile': 'tabular-data-resource',\n 'query': {},\n 'schema': {'fields': [{'name': 'id', 'type': 'integer'},\n                       {'name': 'neighbor_id', 'type': 'integer'},\n                       {'name': 'name', 'type': 'string'},\n                       {'name': 'population', 'type': 'integer'}]},\n 'scheme': 'file',\n 'stats': {'bytes': 100,\n           'fields': 4,\n           'hash': '4204f087f328b70c854c03403ab448c4',\n           'rows': 5}}\n")])]),t._v(" "),e("p",[t._v("The result is really familiar to us already. We have seen it a lot as an output of the "),e("code",[t._v("describe")]),t._v(" function or command. Basically, that’s what this high-level function does under the hood: create a resource and then infer additional metadata.")]),t._v(" "),e("p",[t._v("All main "),e("code",[t._v("Metadata")]),t._v(" classes have this method with different available options but with the same conceptual purpose:")]),t._v(" "),e("ul",[e("li",[e("code",[t._v("package.infer")])]),t._v(" "),e("li",[e("code",[t._v("resource.infer")])]),t._v(" "),e("li",[e("code",[t._v("schema.infer")])])]),t._v(" "),e("h2",{attrs:{id:"expanding-metadata"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#expanding-metadata"}},[t._v("#")]),t._v(" Expanding Metadata")]),t._v(" "),e("p",[t._v("By default, Frictionless never adds default values to metadata, for example:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" describe\n\nresource "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" describe"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"data/country-1.csv"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("pre",[e("code",[t._v("{'fields': [{'name': 'id', 'type': 'integer'},\n            {'name': 'neighbor_id', 'type': 'integer'},\n            {'name': 'name', 'type': 'string'},\n            {'name': 'population', 'type': 'integer'}]}\n")])]),t._v(" "),e("p",[t._v("Under the hood it, for example, still treats empty string as missing values because it’s the specs’ default. We can make reveal implicit metadata by expanding it:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("expand"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("pre",[e("code",[t._v("{'fields': [{'bareNumber': True,\n             'format': 'default',\n             'name': 'id',\n             'type': 'integer'},\n            {'bareNumber': True,\n             'format': 'default',\n             'name': 'neighbor_id',\n             'type': 'integer'},\n            {'format': 'default', 'name': 'name', 'type': 'string'},\n            {'bareNumber': True,\n             'format': 'default',\n             'name': 'population',\n             'type': 'integer'}],\n 'missingValues': ['']}\n")])]),t._v(" "),e("h2",{attrs:{id:"transforming-metadata"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#transforming-metadata"}},[t._v("#")]),t._v(" Transforming Metadata")]),t._v(" "),e("p",[t._v("We have seen it before but let’s re-iterate; it’s possible to transform core metadata properties using Python interface:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Resource\n\nresource "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tmp/country.resource.yaml"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nresource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("title "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Countries"')]),t._v("\nresource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("description "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"It\'s a research project"')]),t._v("\nresource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dialect"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("header_rows "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nresource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dialect"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("delimiter "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('";"')]),t._v("\nresource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_yaml"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tmp/country.resource.yaml"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("But not only the Python interface is available. Thanks to the flexibility of the Frictionless Specs, we can add arbitrary metadata to our descriptor. We use dictionary operations for it:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Resource\n\nresource "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tmp/country.resource.yaml"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nresource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"customKey1"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Value1"')]),t._v("\nresource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"customKey2"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Value2"')]),t._v("\nresource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_yaml"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tmp/country.resource.yaml"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("Let’s check it out:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! cat tmp"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("country"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yaml\n")])])]),e("pre",[e("code",[t._v("compression: 'no'\ncompressionPath: ''\ncontrol:\n  newline: ''\ncustomKey1: Value1\ncustomKey2: Value2\ndescription: It's a research project\ndialect:\n  delimiter: ;\n  headerRows:\n    - 2\nencoding: utf-8\nformat: csv\nhashing: md5\nname: country-2\npath: data/country-2.csv\nprofile: tabular-data-resource\nquery: {}\nschema:\n  fields:\n    - name: id\n      title: Identifier\n      type: integer\n    - name: neighbor_id\n      title: Identifier of the neighbor\n      type: integer\n    - name: name\n      title: Name of the country\n      type: string\n    - constraints:\n        minimum: 0\n      description: According to the year 2020's data\n      name: population\n      title: Population\n      type: integer\n  foreignKeys:\n    - fields:\n        - neighbor_id\n      reference:\n        fields:\n          - id\n        resource: ''\nscheme: file\nstats:\n  bytes: 124\n  fields: 1\n  hash: 88e1901235a8cf35da4d28a1cdf415e5\n  rows: 6\ntitle: Countries\n")])]),t._v(" "),e("h2",{attrs:{id:"validating-metadata"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#validating-metadata"}},[t._v("#")]),t._v(" Validating Metadata")]),t._v(" "),e("p",[t._v("Metadata validity is an important topic so it’s recommended to validate your metadata before publishing. For example, let’s make it invalid:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Resource\n\nresource "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tmp/country.resource.yaml"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nresource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"title"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("metadata_valid"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("metadata_errors"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("pre",[e("code",[t._v("False\n[{'code': 'resource-error', 'name': 'Resource Error', 'tags': ['#general'], 'note': '\"1 is not of type \\'string\\'\" at \"title\" in metadata and at \"properties/title/type\" in profile', 'message': 'The data resource has an error: \"1 is not of type \\'string\\'\" at \"title\" in metadata and at \"properties/title/type\" in profile', 'description': 'A validation cannot be processed.'}]\n")])]),t._v(" "),e("p",[t._v("Let’s fix our resource metadata:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Resource\n\nresource "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tmp/country.resource.yaml"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nresource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"title"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Countries'")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("metadata_valid"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("pre",[e("code",[t._v("True\n")])]),t._v(" "),e("p",[t._v("You need to check "),e("code",[t._v("metadata.metadata_valid")]),t._v(" only if you change it by hands; the available high-level functions like "),e("code",[t._v("validate")]),t._v(" do it on their own.")]),t._v(" "),e("h2",{attrs:{id:"mastering-metadata"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mastering-metadata"}},[t._v("#")]),t._v(" Mastering Metadata")]),t._v(" "),e("p",[t._v("Metadata class is under the hood of many of Frictionless’ classes. Let’s overview main "),e("code",[t._v("Metadata")]),t._v(" features. For a full reference, please read “API Reference”. Let’s take a look at the Metadata class which is a "),e("code",[t._v("dict")]),t._v(" subclass:")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v("Metadata(dict)\n  metadata_attach\n  metadata_extract\n  metadata_process\n  metadata_validate\n  ---\n  metadata_valid\n  metadata_errors\n  ---\n  to_json\n  to_yaml\n")])])]),e("p",[t._v("This class exists for subclassing and here is important points that will help to work with metadata objects and design and write new metadata classes:")]),t._v(" "),e("ul",[e("li",[t._v("to bind default values to a property it’s possible to use "),e("code",[t._v("metadata_attach")]),t._v(" (see e.g. the "),e("code",[t._v("Schema")]),t._v(" class)")]),t._v(" "),e("li",[t._v("during the initialization a descriptor is processed by "),e("code",[t._v("metadata_extract")])]),t._v(" "),e("li",[t._v("metadata detect any shallow update and call "),e("code",[t._v("metadata_process")])]),t._v(" "),e("li",[t._v("checking for validity or errors will trigger "),e("code",[t._v("metadata_validate")])]),t._v(" "),e("li",[t._v("functions exporting to json and yaml are available be default")]),t._v(" "),e("li",[e("code",[t._v("metadata_profile")]),t._v(" can be set to a JSON Schema")]),t._v(" "),e("li",[e("code",[t._v("metadata_Error")]),t._v(" can be set to an Error class")])]),t._v(" "),e("h2",{attrs:{id:"infer-options"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#infer-options"}},[t._v("#")]),t._v(" Infer Options")]),t._v(" "),e("p",[t._v("Let’s explore some handy options to customize the infer process. All of them are available in some form for all the functions above and for different invocation types: in Python, in CLI, or for a REST server.")]),t._v(" "),e("h3",{attrs:{id:"infer-type"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#infer-type"}},[t._v("#")]),t._v(" Infer Type")]),t._v(" "),e("p",[t._v("This option allows manually setting all the field types to a given type. It’s useful when you need to skip datacasting (setting "),e("code",[t._v("any")]),t._v(" type) or have everything as a string (setting "),e("code",[t._v("string")]),t._v(" type):")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("! frictionless describe data"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("country"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.")]),t._v("csv "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("infer"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),t._v(" string\n")])])]),e("pre",[e("code",[t._v("---\nmetadata: data/country-1.csv\n---\n\ncompression: 'no'\ncompressionPath: ''\ncontrol:\n  newline: ''\ndialect: {}\nencoding: utf-8\nformat: csv\nhashing: md5\nname: country-1\npath: data/country-1.csv\nprofile: tabular-data-resource\nquery: {}\nschema:\n  fields:\n    - name: id\n      type: string\n    - name: neighbor_id\n      type: string\n    - name: name\n      type: string\n    - name: population\n      type: string\nscheme: file\nstats:\n  bytes: 100\n  fields: 4\n  hash: 4204f087f328b70c854c03403ab448c4\n  rows: 5\n")])]),t._v(" "),e("h3",{attrs:{id:"infer-names"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#infer-names"}},[t._v("#")]),t._v(" Infer Names")]),t._v(" "),e("p",[t._v("Sometimes you don’t want to use existent header row to compose field names. It’s possible to provide custom names:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" describe\n\nresource "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" describe"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"data/country-1.csv"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" infer_names"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"f1"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"f2"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"f3"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"f4"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field_names"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("pre",[e("code",[t._v("['f1', 'f2', 'f3', 'f4']\n")])]),t._v(" "),e("h3",{attrs:{id:"infer-volume"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#infer-volume"}},[t._v("#")]),t._v(" Infer Volume")]),t._v(" "),e("p",[t._v("By default, Frictionless will use the first 100 rows to detect field types. This can be customized. The following code will be slower but the result can be more accurate")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" describe\n\nresource "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" describe"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"data/country-1.csv"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" infer_volume"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("h3",{attrs:{id:"infer-confidence"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#infer-confidence"}},[t._v("#")]),t._v(" Infer Confidence")]),t._v(" "),e("p",[t._v("By default, Frictionless uses 0.9 (90%) confidence level for data types detection. It means that it there are 9 integers in a field and one string it will be inferred as an integer. If you want a guarantee that an inferred schema will conform to the data you can set it to 1 (100%):")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" describe\n\nresource "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" describe"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"data/country-1.csv"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" infer_confidence"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("h3",{attrs:{id:"infer-missing-values"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#infer-missing-values"}},[t._v("#")]),t._v(" Infer Missing Values")]),t._v(" "),e("p",[t._v("Missing Values is an important concept in data description. It provides information about what cell values should be considered as nulls. We can customize the defaults:")]),t._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pprint "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pprint\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" frictionless "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" describe\n\nresource "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" describe"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"data/country-1.csv"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" infer_missing_values"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"67"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("schema"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("missing_values"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npprint"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resource"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_rows"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("pre",[e("code",[t._v("['', '67']\n[Row([('id', 1),\n      ('neighbor_id', None),\n      ('name', 'Britain'),\n      ('population', None)]),\n Row([('id', 2), ('neighbor_id', 3), ('name', 'France'), ('population', None)]),\n Row([('id', 3), ('neighbor_id', 2), ('name', 'Germany'), ('population', 83)]),\n Row([('id', 4), ('neighbor_id', 5), ('name', 'Italy'), ('population', 60)]),\n Row([('id', 5), ('neighbor_id', 4), ('name', 'Spain'), ('population', 47)])]\n")])]),t._v(" "),e("p",[t._v("As we can see, the textual values equal to “67” are now considered nulls. Usually, it’s handy when you have data with values like: ‘-’, ‘n/a’, and similar.")])])}),[],!1,null,null,null);a.default=n.exports}}]);